{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SU_lch1DySrJ"
   },
   "source": [
    "<img src=\"https://raw.githubusercontent.com/hectormelo/Machine-Learning-Techniques/main/Banner.png\" ><br>\n",
    "# Machine Learning Techniques - MISIS4219\n",
    "\n",
    "Primer semestre - 2024\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5UbZ1aWajfMi"
   },
   "source": [
    "\n",
    "# **Taller 2**\n",
    "\n",
    "GeoAlpes, una empresa líder en análisis geoespacial, está buscando mejorar sus técnicas de clasificación automática de imágenes satelitales. El objetivo es poder categorizar distintas características geográficas (como bosques, zonas industriales, zonas de cultivos permanentes, zonas residenciales y rios) con alta precisión y rapidez. Para lograrlo, están interesados en explorar las capacidades de los métodos ensemble.\n",
    "\n",
    "1.  Exploración y Preparación de Datos\n",
    "\n",
    "    -   Discuta las particularidades de las imágenes satelitales y sugiera técnicas extra de preprocesamiento de ser necesario.\n",
    "\n",
    "2.  Implementación de Gradient Boosting\n",
    "\n",
    "    -   Utilice Gradient Boosting como modelo base. Discuta las ventajas y desafíos de este método, y cómo afecta la precisión y robustez del clasificador. Además, compare el desempeño de Gradient Boosting con el modelo Random Forest presentado en la práctica, ¿logra observar mejoras significativas?\n",
    "\n",
    "3. Implementación de un nuevo metodo Ensemble\n",
    "    - Elija y presente un método ensemble de su preferencia.Introduzca y discuta el concepto del método elegido y cómo podría ser benéfico para la clasificación de imágenes satelitales.\n",
    "    - Compare el desempeño de su método elegido con Gradient Boosting y el modelo Random Forest. Discuta las ventajas y desventajas de cada uno.\n",
    "\n",
    "4.  Optimización y Ajuste\n",
    "\n",
    "    -   Realice una búsqueda de los mejores hiperparámetros para mejorar el desempeño de cada uno de los modelos implementados (Grid Search).\n",
    "\n",
    "Datos: [Enlace al sub conjunto del dataset de imágenes satelitales EuroSAT](https://github.com/hectormelo/Machine-Learning-Techniques/raw/main/Lab_2/EuroSAT3.zip)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j1mByJGEgHEA"
   },
   "source": [
    "# **DESARROLLO TALLER 2:**\n",
    "\n",
    "* William Ravelo - 201532093\n",
    "* Jose Moreno    - 201011998\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ajt4RZY9haTz"
   },
   "source": [
    "# Paso 0: Importación de librerias relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "OrbH-WvDgFaz"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "import requests\n",
    "\n",
    "from sklearn.metrics import accuracy_score # Cálculo de la precisión\n",
    "from sklearn.decomposition import PCA # Análisis de componentes principales\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay # Matriz de confusión\n",
    "from sklearn.model_selection import train_test_split # División de datos en entrenamiento y prueba\n",
    "from sklearn.model_selection import GridSearchCV # Búsqueda de hiperparámetros\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler # Estandarización de datos\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score # Reporte de clasificación y precisión\n",
    "from sklearn.svm import SVC # Máquina de soporte vectorial\n",
    "from sklearn.ensemble import RandomForestClassifier #Librería para manejo del algoritmo Random Forest\n",
    "\n",
    "from PIL import Image #Librería para brir, manipular y guardar muchos formatos diferentes de archivos de imágenes.\n",
    "\n",
    "from skimage import io\n",
    "from zipfile import ZipFile\n",
    "from io import BytesIO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QR_oxFCxgEEF"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2inTsa-Ahkym"
   },
   "source": [
    "# Paso 1: Preparación + exploración + preprocesamiento de los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "G96HHY23hqBg"
   },
   "outputs": [
    {
     "ename": "BadZipFile",
     "evalue": "File is not a zip file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadZipFile\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m zip_content \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mcontent\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Descomprimir el contenido en memoria\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mZipFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBytesIO\u001b[49m\u001b[43m(\u001b[49m\u001b[43mzip_content\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m zip_file:\n\u001b[1;32m     10\u001b[0m     zip_file\u001b[38;5;241m.\u001b[39mextractall(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/content/data/EuroSAT\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Especifica el directorio donde quieres descomprimir\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArchivo descomprimido.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda/lib/python3.11/zipfile.py:1302\u001b[0m, in \u001b[0;36mZipFile.__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps, metadata_encoding)\u001b[0m\n\u001b[1;32m   1300\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1301\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m-> 1302\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_RealGetContents\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1303\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m   1304\u001b[0m         \u001b[38;5;66;03m# set the modified flag so central directory gets written\u001b[39;00m\n\u001b[1;32m   1305\u001b[0m         \u001b[38;5;66;03m# even if no files are added to the archive\u001b[39;00m\n\u001b[1;32m   1306\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_didModify \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.11/zipfile.py:1369\u001b[0m, in \u001b[0;36mZipFile._RealGetContents\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1367\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BadZipFile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile is not a zip file\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1368\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m endrec:\n\u001b[0;32m-> 1369\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BadZipFile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile is not a zip file\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdebug \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1371\u001b[0m     \u001b[38;5;28mprint\u001b[39m(endrec)\n",
      "\u001b[0;31mBadZipFile\u001b[0m: File is not a zip file"
     ]
    }
   ],
   "source": [
    "# URL con data en archivo ZIP\n",
    "# url = 'https://github.com/hectormelo/Machine-Learning-Techniques/raw/main/Lab_2/EuroSAT3.zip'\n",
    "url = 'https://github.com/JoseMoCa/ML_techniques/blob/6f38ee040fbbd1981e8c23f956f7fe681a333bfa/Taller%202/EuroSAT3.zip'\n",
    "\n",
    "# Descargar el archivo ZIP\n",
    "response = requests.get(url)\n",
    "zip_content = response.content\n",
    "# Descomprimir el contenido en memoria\n",
    "with ZipFile(BytesIO(zip_content)) as zip_file:\n",
    "    zip_file.extractall(\"/content/data/EuroSAT\")  # Especifica el directorio donde quieres descomprimir\n",
    "print(\"Archivo descomprimido.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
